{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwFdfr69VANz"
      },
      "source": [
        "# ðŸš¨ BVMT Anomaly Detection System\n",
        "## Market Surveillance & Alert Generation\n",
        "\n",
        "**Objective:** Detect suspicious market activity in BVMT stocks\n",
        "\n",
        "**Detection Types:**\n",
        "- Volume spikes (>3 standard deviations)\n",
        "- Abnormal price movements (>5% without news)\n",
        "- Unusual trading patterns\n",
        "\n",
        "**Model:** Isolation Forest + Rule-Based Thresholds (Hybrid Approach)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBuPdBxPVAN0"
      },
      "source": [
        "## 1. Setup & Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3VmuydV1VAN1"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-learn pandas numpy matplotlib seaborn joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8TGsZhmVAN2",
        "outputId": "fd92d81f-1dd0-45d5-983f-eb801a6ab0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Libraries imported\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "print(\"âœ… Libraries imported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_CFSGjSVAN2"
      },
      "outputs": [],
      "source": [
        "# Upload data files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm_CGA_6VAN2",
        "outputId": "dd0cbc3c-0c1c-4441-8362-51c4855bf698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 2022: 83939 rows\n",
            "âœ… Loaded 2023: 147209 rows\n",
            "âœ… Loaded 2024: 145381 rows\n",
            "âœ… Loaded 2025: 142853 rows\n"
          ]
        }
      ],
      "source": [
        "# Load data (reuse from price prediction notebook)\n",
        "def load_csv_file(filepath):\n",
        "    df = pd.read_csv(filepath, sep=';', encoding='utf-8')\n",
        "    df.columns = df.columns.str.strip()\n",
        "    return df\n",
        "\n",
        "def load_all_recent_data():\n",
        "    \"\"\"Load 2022-2025 data for anomaly detection (more recent = more relevant)\"\"\"\n",
        "    all_dfs = []\n",
        "    for year in range(2022, 2026):\n",
        "        try:\n",
        "            df = load_csv_file(f'/content/histo_cotation_{year}.csv')\n",
        "            all_dfs.append(df)\n",
        "            print(f\"âœ… Loaded {year}: {len(df)} rows\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Could not load {year}: {e}\")\n",
        "\n",
        "    return pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "raw_data = load_all_recent_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8WoZYBIVAN3",
        "outputId": "8250fec0-8819-4a28-ea62-292b64c210c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” SEANCE sample: ['03/01/2022   ', '03/01/2022   ', '03/01/2022   ']\n",
            "   SEANCE dtype: object\n",
            "ðŸ“… Valid dates: 204601\n",
            "âœ… Cleaned data: 16053 rows\n"
          ]
        }
      ],
      "source": [
        "def clean_data(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Debug: Check SEANCE format first\n",
        "    print(f\"ðŸ” SEANCE sample: {df['SEANCE'].head(3).tolist()}\")\n",
        "    print(f\"   SEANCE dtype: {df['SEANCE'].dtype}\")\n",
        "\n",
        "    # Parse date - let pandas infer the format automatically\n",
        "    df['date'] = pd.to_datetime(df['SEANCE'], errors='coerce')\n",
        "\n",
        "    # If auto-detection fails, try common formats\n",
        "    if df['date'].isna().all():\n",
        "        for fmt in ['%Y-%m-%d', '%d-%m-%Y', '%m/%d/%Y', '%d/%m/%Y', '%Y%m%d']:\n",
        "            df['date'] = pd.to_datetime(df['SEANCE'], format=fmt, errors='coerce')\n",
        "            if df['date'].notna().any():\n",
        "                print(f\"   âœ… Date format detected: {fmt}\")\n",
        "                break\n",
        "\n",
        "    print(f\"ðŸ“… Valid dates: {df['date'].notna().sum()}\")\n",
        "\n",
        "    # Filter to main market\n",
        "    df['GROUPE'] = pd.to_numeric(df['GROUPE'], errors='coerce')\n",
        "    df = df[df['GROUPE'] == 11].copy()\n",
        "\n",
        "    # Rename columns\n",
        "    df = df.rename(columns={\n",
        "        'VALEUR': 'stock_name',\n",
        "        'CODE': 'stock_code',\n",
        "        'OUVERTURE': 'open',\n",
        "        'CLOTURE': 'close',\n",
        "        'PLUS_BAS': 'low',\n",
        "        'PLUS_HAUT': 'high',\n",
        "        'QUANTITE_NEGOCIEE': 'volume',\n",
        "        'NB_TRANSACTION': 'transactions',\n",
        "        'CAPITAUX': 'capital'\n",
        "    })\n",
        "\n",
        "    # Convert numeric\n",
        "    for col in ['open', 'close', 'low', 'high', 'volume', 'transactions', 'capital']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Filter valid data\n",
        "    df = df.dropna(subset=['date', 'close'])\n",
        "    df = df[(df['close'] > 0) & (df['volume'] > 0)]\n",
        "\n",
        "    return df.sort_values(['stock_name', 'date']).reset_index(drop=True)\n",
        "\n",
        "data = clean_data(raw_data)\n",
        "print(f\"âœ… Cleaned data: {len(data)} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXn_53o0VAN3"
      },
      "source": [
        "## 2. Anomaly Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "werqmCtjVAN3",
        "outputId": "8fcbc7b5-bad7-4646-b564-e2e3411b215b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Feature-enriched data: 14869 rows\n"
          ]
        }
      ],
      "source": [
        "def create_anomaly_features(df):\n",
        "    \"\"\"\n",
        "    Create features specifically for anomaly detection.\n",
        "    These features capture unusual market behavior.\n",
        "    \"\"\"\n",
        "    df = df.copy().sort_values('date').reset_index(drop=True)\n",
        "\n",
        "    # Volume-based anomaly features\n",
        "    df['volume_ma_20'] = df['volume'].rolling(20).mean()\n",
        "    df['volume_std_20'] = df['volume'].rolling(20).std()\n",
        "    df['volume_zscore'] = (df['volume'] - df['volume_ma_20']) / df['volume_std_20']\n",
        "    df['volume_ratio'] = df['volume'] / df['volume_ma_20']\n",
        "\n",
        "    # Price-based anomaly features\n",
        "    df['price_change'] = df['close'].pct_change()\n",
        "    df['price_change_abs'] = df['price_change'].abs()\n",
        "    df['price_ma_20'] = df['close'].rolling(20).mean()\n",
        "    df['price_std_20'] = df['close'].rolling(20).std()\n",
        "    df['price_zscore'] = (df['close'] - df['price_ma_20']) / df['price_std_20']\n",
        "\n",
        "    # Intraday range (high volatility indicator)\n",
        "    df['intraday_range'] = (df['high'] - df['low']) / df['close']\n",
        "    df['range_ma_10'] = df['intraday_range'].rolling(10).mean()\n",
        "    df['range_ratio'] = df['intraday_range'] / df['range_ma_10']\n",
        "\n",
        "    # Gap analysis (opening gap from previous close)\n",
        "    df['gap_open'] = (df['open'] - df['close'].shift(1)) / df['close'].shift(1)\n",
        "    df['gap_open_abs'] = df['gap_open'].abs()\n",
        "\n",
        "    # Transaction anomaly\n",
        "    df['tx_ma_20'] = df['transactions'].rolling(20).mean()\n",
        "    df['tx_ratio'] = df['transactions'] / df['tx_ma_20']\n",
        "\n",
        "    # Volume-Price divergence (high volume but small price change = suspicious)\n",
        "    df['vol_price_ratio'] = df['volume_ratio'] / (df['price_change_abs'] + 0.001)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply to each stock\n",
        "featured_data = []\n",
        "for stock in data['stock_name'].unique():\n",
        "    stock_df = data[data['stock_name'] == stock].copy()\n",
        "    if len(stock_df) >= 30:  # Need minimum history\n",
        "        stock_df = create_anomaly_features(stock_df)\n",
        "        featured_data.append(stock_df)\n",
        "\n",
        "data_with_features = pd.concat(featured_data, ignore_index=True)\n",
        "data_with_features = data_with_features.dropna()\n",
        "print(f\"âœ… Feature-enriched data: {len(data_with_features)} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3v4gjM5VAN4"
      },
      "source": [
        "## 3. Rule-Based Detection (Fast & Interpretable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ggiV8pEVAN4",
        "outputId": "e326fedd-9867-4b34-cf7c-1f0eb9379214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Rule-Based Anomaly Detection Results:\n",
            "  Volume Spikes: 440 (2.96%)\n",
            "  Price Anomalies: 6941 (46.68%)\n",
            "  Gap Anomalies: 9249 (62.20%)\n",
            "  Range Anomalies: 1498 (10.07%)\n"
          ]
        }
      ],
      "source": [
        "def detect_volume_spike(row, threshold=3.0):\n",
        "    \"\"\"Detect if volume is abnormally high (> threshold standard deviations)\"\"\"\n",
        "    return row['volume_zscore'] > threshold\n",
        "\n",
        "def detect_price_anomaly(row, threshold=0.05):\n",
        "    \"\"\"Detect if price change is abnormally high (> threshold %)\"\"\"\n",
        "    return row['price_change_abs'] > threshold\n",
        "\n",
        "def detect_gap_anomaly(row, threshold=0.03):\n",
        "    \"\"\"Detect if opening gap is abnormal (> threshold %)\"\"\"\n",
        "    return row['gap_open_abs'] > threshold\n",
        "\n",
        "def detect_range_anomaly(row, threshold=2.0):\n",
        "    \"\"\"Detect if intraday range is abnormal\"\"\"\n",
        "    return row['range_ratio'] > threshold\n",
        "\n",
        "# Apply rule-based detection\n",
        "df = data_with_features.copy()\n",
        "df['is_volume_spike'] = df.apply(detect_volume_spike, axis=1)\n",
        "df['is_price_anomaly'] = df.apply(detect_price_anomaly, axis=1)\n",
        "df['is_gap_anomaly'] = df.apply(detect_gap_anomaly, axis=1)\n",
        "df['is_range_anomaly'] = df.apply(detect_range_anomaly, axis=1)\n",
        "\n",
        "# Count anomalies per type\n",
        "print(\"ðŸ“Š Rule-Based Anomaly Detection Results:\")\n",
        "print(f\"  Volume Spikes: {df['is_volume_spike'].sum()} ({df['is_volume_spike'].mean()*100:.2f}%)\")\n",
        "print(f\"  Price Anomalies: {df['is_price_anomaly'].sum()} ({df['is_price_anomaly'].mean()*100:.2f}%)\")\n",
        "print(f\"  Gap Anomalies: {df['is_gap_anomaly'].sum()} ({df['is_gap_anomaly'].mean()*100:.2f}%)\")\n",
        "print(f\"  Range Anomalies: {df['is_range_anomaly'].sum()} ({df['is_range_anomaly'].mean()*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od-6vKzaVAN4"
      },
      "source": [
        "## 4. Isolation Forest (ML-Based Detection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAvV7P6mVAN4",
        "outputId": "fb1c0d22-41a7-4679-8a72-f4f80c36e788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Prepared 14869 samples with 9 features\n"
          ]
        }
      ],
      "source": [
        "# Features for Isolation Forest\n",
        "ANOMALY_FEATURES = [\n",
        "    'volume_zscore',\n",
        "    'volume_ratio',\n",
        "    'price_change_abs',\n",
        "    'price_zscore',\n",
        "    'intraday_range',\n",
        "    'range_ratio',\n",
        "    'gap_open_abs',\n",
        "    'tx_ratio',\n",
        "    'vol_price_ratio'\n",
        "]\n",
        "\n",
        "# Prepare data\n",
        "X = df[ANOMALY_FEATURES].values\n",
        "X = np.nan_to_num(X, nan=0, posinf=0, neginf=0)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"âœ… Prepared {len(X)} samples with {len(ANOMALY_FEATURES)} features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp0ZrIacVAN5",
        "outputId": "0a2969cc-4c42-44d7-d16d-fc8e372e1e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Isolation Forest Results:\n",
            "  ML Anomalies: 298 (2.00%)\n"
          ]
        }
      ],
      "source": [
        "# Train Isolation Forest\n",
        "# contamination = expected proportion of anomalies (1-2% is typical for market data)\n",
        "iso_forest = IsolationForest(\n",
        "    n_estimators=200,\n",
        "    max_samples='auto',\n",
        "    contamination=0.02,  # Expect 2% anomalies\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit and predict\n",
        "df['iso_forest_label'] = iso_forest.fit_predict(X_scaled)\n",
        "df['iso_forest_score'] = iso_forest.decision_function(X_scaled)\n",
        "\n",
        "# -1 = anomaly, 1 = normal\n",
        "df['is_ml_anomaly'] = df['iso_forest_label'] == -1\n",
        "\n",
        "print(f\"\\nðŸ“Š Isolation Forest Results:\")\n",
        "print(f\"  ML Anomalies: {df['is_ml_anomaly'].sum()} ({df['is_ml_anomaly'].mean()*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbLPDPpSVAN5",
        "outputId": "f6766581-9117-4cb3-e5d1-f3d41c157093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Anomaly Severity Distribution:\n",
            "severity\n",
            "MEDIUM    6769\n",
            "NONE      4974\n",
            "LOW       2757\n",
            "HIGH       369\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Combine rule-based and ML detection (hybrid approach)\n",
        "df['anomaly_score'] = (\n",
        "    df['is_volume_spike'].astype(int) * 0.3 +\n",
        "    df['is_price_anomaly'].astype(int) * 0.3 +\n",
        "    df['is_gap_anomaly'].astype(int) * 0.1 +\n",
        "    df['is_range_anomaly'].astype(int) * 0.1 +\n",
        "    df['is_ml_anomaly'].astype(int) * 0.2\n",
        ")\n",
        "\n",
        "# Classify severity\n",
        "def classify_severity(score):\n",
        "    if score >= 0.6:\n",
        "        return 'HIGH'\n",
        "    elif score >= 0.3:\n",
        "        return 'MEDIUM'\n",
        "    elif score > 0:\n",
        "        return 'LOW'\n",
        "    return 'NONE'\n",
        "\n",
        "df['severity'] = df['anomaly_score'].apply(classify_severity)\n",
        "\n",
        "# Summary\n",
        "print(\"\\nðŸ“Š Anomaly Severity Distribution:\")\n",
        "print(df['severity'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2I9nXUcVAN5"
      },
      "source": [
        "## 5. Visualize Anomalies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaFrh8DqVAN5",
        "outputId": "ee2e2872-539a-4c2d-84ca-fb9907492a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸš¨ Top 20 Detected Anomalies:\n",
            "            date          stock_name  close  volume  price_change  volume_zscore severity  anomaly_score\n",
            "2531  2023-01-06  ATTIJARI BANK       46.00   16086      0.179790       3.631483     HIGH            1.0\n",
            "11091 2022-07-02  SOPAT                1.65   48886      0.213235       3.147484     HIGH            1.0\n",
            "2994  2024-04-01  ATTIJARI LEASING    16.50    3101     -0.136126       4.096392     HIGH            1.0\n",
            "15175 2025-08-01  TUNISIE LEASING F   17.98   25060     -0.457617       3.297481     HIGH            1.0\n",
            "15238 2022-03-11  UIB                 23.82  204245      0.151281       4.219358     HIGH            1.0\n",
            "8489  2025-05-05  OFFICEPLAST          1.75   34340      0.093750       4.219863     HIGH            1.0\n",
            "8821  2024-10-10  ONE TECH HOLDING     9.88  388721      0.079781       3.477609     HIGH            1.0\n",
            "11880 2025-02-05  SOTIPAPIER           3.72   49777     -0.160271       3.454119     HIGH            1.0\n",
            "7652  2025-07-11  LAND OR             13.00   67813      0.238095       3.578631     HIGH            1.0\n",
            "7737  2022-07-06  MONOPRIX             5.01  120272      0.343164       3.483558     HIGH            1.0\n",
            "12627 2025-03-01  SOTUMAG              6.42    9013     -0.294505       3.719097     HIGH            1.0\n",
            "7973  2024-04-12  MPBS                12.38   24105      0.082168       3.935501     HIGH            1.0\n",
            "13048 2025-06-03  SOTUVER             14.50   59757      0.117103       3.602820     HIGH            1.0\n",
            "12744 2022-05-09  SOTUVER              9.29   72517      0.100711       3.495198     HIGH            1.0\n",
            "7214  2024-09-10  ICF                 82.99    5587      0.074304       4.016068     HIGH            1.0\n",
            "7515  2024-02-05  LAND OR              7.46   25602      0.224959       3.421686     HIGH            1.0\n",
            "6785  2024-04-09  EURO-CYCLES         13.79   57136      0.209649       4.029641     HIGH            1.0\n",
            "6880  2025-04-03  EURO-CYCLES         15.44   51275      0.230279       3.757013     HIGH            1.0\n",
            "7121  2023-10-01  ICF                 98.70    4525      0.410403       4.015279     HIGH            1.0\n",
            "15056 2024-04-04  TUNISIE LEASING F   15.20  150334      0.144578       4.221880     HIGH            1.0\n"
          ]
        }
      ],
      "source": [
        "# Show top anomalies\n",
        "top_anomalies = df[df['severity'].isin(['HIGH', 'MEDIUM'])].sort_values('anomaly_score', ascending=False).head(20)\n",
        "\n",
        "print(\"\\nðŸš¨ Top 20 Detected Anomalies:\")\n",
        "display_cols = ['date', 'stock_name', 'close', 'volume', 'price_change', 'volume_zscore', 'severity', 'anomaly_score']\n",
        "print(top_anomalies[display_cols].to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RUCH8A7FVAN5"
      },
      "outputs": [],
      "source": [
        "# Visualize anomalies for a sample stock\n",
        "sample_stock = 'SFBT'\n",
        "stock_data = df[df['stock_name'] == sample_stock].copy()\n",
        "\n",
        "if len(stock_data) > 0:\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "    # Price with anomalies\n",
        "    ax1 = axes[0]\n",
        "    ax1.plot(stock_data['date'], stock_data['close'], color='white', linewidth=1, label='Price')\n",
        "\n",
        "    # Mark anomalies\n",
        "    high_anomalies = stock_data[stock_data['severity'] == 'HIGH']\n",
        "    medium_anomalies = stock_data[stock_data['severity'] == 'MEDIUM']\n",
        "\n",
        "    ax1.scatter(high_anomalies['date'], high_anomalies['close'],\n",
        "                color='#ff4444', s=100, label='HIGH Severity', zorder=5)\n",
        "    ax1.scatter(medium_anomalies['date'], medium_anomalies['close'],\n",
        "                color='#ffaa00', s=50, label='MEDIUM Severity', zorder=4)\n",
        "\n",
        "    ax1.set_title(f'{sample_stock} - Price with Anomalies', color='white')\n",
        "    ax1.legend()\n",
        "    ax1.grid(alpha=0.3)\n",
        "\n",
        "    # Volume with anomalies\n",
        "    ax2 = axes[1]\n",
        "    ax2.bar(stock_data['date'], stock_data['volume'], color='#444444', alpha=0.7, label='Volume')\n",
        "    ax2.bar(high_anomalies['date'], high_anomalies['volume'], color='#ff4444', label='Spike')\n",
        "\n",
        "    ax2.set_title(f'{sample_stock} - Volume with Spikes', color='white')\n",
        "    ax2.legend()\n",
        "    ax2.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27rx4WVlVAN5"
      },
      "source": [
        "## 6. Export Model & Alert Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFTwdgw8VAN5",
        "outputId": "aa870eda-3082-45e4-9b0a-0e4ac80fa372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved models/anomaly_detector.pkl\n",
            "âœ… Saved models/anomaly_scaler.pkl\n",
            "âœ… Saved models/anomaly_config.json\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import json\n",
        "import os\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Save Isolation Forest model\n",
        "joblib.dump(iso_forest, 'models/anomaly_detector.pkl')\n",
        "print(\"âœ… Saved models/anomaly_detector.pkl\")\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, 'models/anomaly_scaler.pkl')\n",
        "print(\"âœ… Saved models/anomaly_scaler.pkl\")\n",
        "\n",
        "# Save config\n",
        "anomaly_config = {\n",
        "    'feature_columns': ANOMALY_FEATURES,\n",
        "    'thresholds': {\n",
        "        'volume_spike_zscore': 3.0,\n",
        "        'price_change_pct': 0.05,\n",
        "        'gap_open_pct': 0.03,\n",
        "        'range_ratio': 2.0\n",
        "    },\n",
        "    'severity_levels': {\n",
        "        'HIGH': 0.6,\n",
        "        'MEDIUM': 0.3,\n",
        "        'LOW': 0.0\n",
        "    },\n",
        "    'contamination': 0.02,\n",
        "    'created_at': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "with open('models/anomaly_config.json', 'w') as f:\n",
        "    json.dump(anomaly_config, f, indent=2)\n",
        "print(\"âœ… Saved models/anomaly_config.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wr06fgjVAN5"
      },
      "outputs": [],
      "source": [
        "# Download models\n",
        "!zip -r anomaly_models.zip models/\n",
        "files.download('anomaly_models.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlfSoJizVAN5"
      },
      "source": [
        "## 7. Inference Class (for Backend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b46lXHoFVAN6"
      },
      "outputs": [],
      "source": [
        "# === COPY THIS TO YOUR BACKEND ===\n",
        "\n",
        "class BVMTAnomalyDetector:\n",
        "    \"\"\"\n",
        "    Production-ready anomaly detection service for BVMT stocks.\n",
        "\n",
        "    Combines rule-based thresholds with Isolation Forest for robust detection.\n",
        "    \"\"\"\n",
        "\n",
        "    THRESHOLDS = {\n",
        "        'volume_spike_zscore': 3.0,\n",
        "        'price_change_pct': 0.05,\n",
        "        'gap_open_pct': 0.03,\n",
        "        'range_ratio': 2.0\n",
        "    }\n",
        "\n",
        "    FEATURE_COLS = [\n",
        "        'volume_zscore', 'volume_ratio', 'price_change_abs', 'price_zscore',\n",
        "        'intraday_range', 'range_ratio', 'gap_open_abs', 'tx_ratio', 'vol_price_ratio'\n",
        "    ]\n",
        "\n",
        "    def __init__(self, model_dir: str):\n",
        "        self.model_dir = model_dir\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "        self._load_models()\n",
        "\n",
        "    def _load_models(self):\n",
        "        import joblib\n",
        "        try:\n",
        "            self.model = joblib.load(f'{self.model_dir}/anomaly_detector.pkl')\n",
        "            self.scaler = joblib.load(f'{self.model_dir}/anomaly_scaler.pkl')\n",
        "            print(\"âœ… Anomaly detection models loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Could not load models: {e}\")\n",
        "\n",
        "    def detect(self, stock_name: str, current_data: dict, historical_stats: dict) -> dict:\n",
        "        \"\"\"\n",
        "        Detect anomalies for a single data point.\n",
        "\n",
        "        Args:\n",
        "            stock_name: Name of stock\n",
        "            current_data: Dict with keys [open, high, low, close, volume, transactions]\n",
        "            historical_stats: Dict with keys [volume_ma_20, volume_std_20, price_ma_20, price_std_20, etc.]\n",
        "\n",
        "        Returns:\n",
        "            Anomaly detection result\n",
        "        \"\"\"\n",
        "        # Calculate features\n",
        "        features = self._calculate_features(current_data, historical_stats)\n",
        "\n",
        "        # Rule-based detection\n",
        "        alerts = []\n",
        "        severity_score = 0\n",
        "\n",
        "        if features['volume_zscore'] > self.THRESHOLDS['volume_spike_zscore']:\n",
        "            alerts.append({\n",
        "                'type': 'VOLUME_SPIKE',\n",
        "                'message': f\"Volume is {features['volume_zscore']:.1f}Ïƒ above average\",\n",
        "                'severity': 'HIGH' if features['volume_zscore'] > 5 else 'MEDIUM'\n",
        "            })\n",
        "            severity_score += 0.3\n",
        "\n",
        "        if features['price_change_abs'] > self.THRESHOLDS['price_change_pct']:\n",
        "            direction = 'up' if features.get('price_change', 0) > 0 else 'down'\n",
        "            alerts.append({\n",
        "                'type': 'PRICE_MOVE',\n",
        "                'message': f\"Price moved {features['price_change_abs']*100:.1f}% {direction}\",\n",
        "                'severity': 'HIGH' if features['price_change_abs'] > 0.10 else 'MEDIUM'\n",
        "            })\n",
        "            severity_score += 0.3\n",
        "\n",
        "        if features['gap_open_abs'] > self.THRESHOLDS['gap_open_pct']:\n",
        "            alerts.append({\n",
        "                'type': 'GAP_OPEN',\n",
        "                'message': f\"Gap open of {features['gap_open_abs']*100:.1f}%\",\n",
        "                'severity': 'MEDIUM'\n",
        "            })\n",
        "            severity_score += 0.1\n",
        "\n",
        "        # ML-based detection\n",
        "        if self.model and self.scaler:\n",
        "            X = np.array([[features.get(col, 0) for col in self.FEATURE_COLS]])\n",
        "            X = np.nan_to_num(X, nan=0, posinf=0, neginf=0)\n",
        "            X_scaled = self.scaler.transform(X)\n",
        "\n",
        "            ml_prediction = self.model.predict(X_scaled)[0]\n",
        "            ml_score = self.model.decision_function(X_scaled)[0]\n",
        "\n",
        "            if ml_prediction == -1:  # Anomaly\n",
        "                alerts.append({\n",
        "                    'type': 'ML_ANOMALY',\n",
        "                    'message': f\"Unusual pattern detected (score: {ml_score:.3f})\",\n",
        "                    'severity': 'MEDIUM'\n",
        "                })\n",
        "                severity_score += 0.2\n",
        "\n",
        "        # Determine overall severity\n",
        "        if severity_score >= 0.6:\n",
        "            overall_severity = 'HIGH'\n",
        "        elif severity_score >= 0.3:\n",
        "            overall_severity = 'MEDIUM'\n",
        "        elif severity_score > 0:\n",
        "            overall_severity = 'LOW'\n",
        "        else:\n",
        "            overall_severity = 'NONE'\n",
        "\n",
        "        return {\n",
        "            'stock': stock_name,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'is_anomaly': len(alerts) > 0,\n",
        "            'severity': overall_severity,\n",
        "            'severity_score': round(severity_score, 2),\n",
        "            'alerts': alerts,\n",
        "            'features': {k: round(v, 4) if isinstance(v, float) else v for k, v in features.items()}\n",
        "        }\n",
        "\n",
        "    def _calculate_features(self, current: dict, historical: dict) -> dict:\n",
        "        \"\"\"Calculate anomaly detection features from current and historical data.\"\"\"\n",
        "        volume = current.get('volume', 0)\n",
        "        close = current.get('close', 0)\n",
        "        open_price = current.get('open', close)\n",
        "        high = current.get('high', close)\n",
        "        low = current.get('low', close)\n",
        "        prev_close = historical.get('prev_close', close)\n",
        "\n",
        "        vol_ma = historical.get('volume_ma_20', volume)\n",
        "        vol_std = historical.get('volume_std_20', 1)\n",
        "        price_ma = historical.get('price_ma_20', close)\n",
        "        price_std = historical.get('price_std_20', 1)\n",
        "        range_ma = historical.get('range_ma_10', 0.01)\n",
        "        tx_ma = historical.get('tx_ma_20', 1)\n",
        "\n",
        "        price_change = (close - prev_close) / prev_close if prev_close > 0 else 0\n",
        "        intraday_range = (high - low) / close if close > 0 else 0\n",
        "        gap_open = (open_price - prev_close) / prev_close if prev_close > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'volume_zscore': (volume - vol_ma) / vol_std if vol_std > 0 else 0,\n",
        "            'volume_ratio': volume / vol_ma if vol_ma > 0 else 1,\n",
        "            'price_change': price_change,\n",
        "            'price_change_abs': abs(price_change),\n",
        "            'price_zscore': (close - price_ma) / price_std if price_std > 0 else 0,\n",
        "            'intraday_range': intraday_range,\n",
        "            'range_ratio': intraday_range / range_ma if range_ma > 0 else 1,\n",
        "            'gap_open_abs': abs(gap_open),\n",
        "            'tx_ratio': current.get('transactions', 0) / tx_ma if tx_ma > 0 else 1,\n",
        "            'vol_price_ratio': (volume / vol_ma) / (abs(price_change) + 0.001) if vol_ma > 0 else 0\n",
        "        }\n",
        "\n",
        "print(\"âœ… BVMTAnomalyDetector class ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRgg4_26VAN6"
      },
      "source": [
        "## Summary\n",
        "\n",
        "### What We Built:\n",
        "1. âœ… Rule-based detection (volume spikes, price moves, gaps)\n",
        "2. âœ… Isolation Forest ML detection\n",
        "3. âœ… Hybrid scoring with severity levels\n",
        "4. âœ… Production-ready inference class\n",
        "\n",
        "### Files to Copy:\n",
        "```\n",
        "ml/models/\n",
        "â”œâ”€â”€ anomaly_detector.pkl\n",
        "â”œâ”€â”€ anomaly_scaler.pkl\n",
        "â””â”€â”€ anomaly_config.json\n",
        "```\n",
        "\n",
        "### Backend Integration:\n",
        "Copy `BVMTAnomalyDetector` class to `backend/app/services/anomaly.py`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}